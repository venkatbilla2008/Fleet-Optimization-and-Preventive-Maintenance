# Databricks notebook source
# MAGIC %md
# MAGIC # 01 - Bronze Layer Ingestion (IMPROVED)
# MAGIC 
# MAGIC ## Fleet Optimization & Predictive Maintenance
# MAGIC 
# MAGIC **Purpose:** Generate realistic vehicle data with improved variation for better ML performance
# MAGIC 
# MAGIC **Improvements:**
# MAGIC - 500 vehicles (was 100) - 5x more data
# MAGIC - 30 days of data (was 7) - 4x more temporal data
# MAGIC - 5 health categories (was 3) - Better variation
# MAGIC - Gradual degradation patterns - More realistic
# MAGIC 
# MAGIC **Expected ML Performance:**
# MAGIC - F1-Score: 92-95% (was 88%)
# MAGIC - ROC-AUC: 90-95% (was 75%)
# MAGIC 
# MAGIC **Author:** Venkat M  
# MAGIC **Date:** 2026-01-27

# COMMAND ----------

# MAGIC %md
# MAGIC ## 1. Configuration & Imports

# COMMAND ----------

from pyspark.sql.functions import *
from pyspark.sql.types import *
from datetime import datetime, timedelta
import random

# Configuration (Community Edition - No Unity Catalog)
BRONZE_SCHEMA = "bronze_schema"

# Data generation parameters (IMPROVED)
NUM_VEHICLES = 500  # Increased from 100
START_DATE = datetime(2024, 1, 1)
END_DATE = datetime(2024, 1, 30)  # Increased from 7 to 30 days
READINGS_PER_DAY = 144  # Every 10 minutes

print("=" * 60)
print("Bronze Layer Ingestion (IMPROVED)")
print("=" * 60)
print(f"Schema: {BRONZE_SCHEMA}")
print(f"Vehicles: {NUM_VEHICLES}")
print(f"Date Range: {START_DATE.date()} to {END_DATE.date()}")
print(f"Days: {(END_DATE - START_DATE).days}")
print(f"Readings per day: {READINGS_PER_DAY}")
print(f"Expected total GPS records: {NUM_VEHICLES * (END_DATE - START_DATE).days * READINGS_PER_DAY:,}")
print("=" * 60)

# Create schema
spark.sql(f"CREATE SCHEMA IF NOT EXISTS {BRONZE_SCHEMA}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 2. Generate GPS Tracking Data

# COMMAND ----------

print("Generating GPS tracking data...")

gps_data = []
for vehicle_id in range(1, NUM_VEHICLES + 1):
    current_date = START_DATE
    # Start location (distributed around NYC)
    lat = 40.7128 + random.uniform(-0.5, 0.5)
    lon = -74.0060 + random.uniform(-0.5, 0.5)
    
    while current_date <= END_DATE:
        for reading in range(READINGS_PER_DAY):
            timestamp = current_date + timedelta(minutes=reading * 10)
            
            # Simulate realistic movement
            lat += random.uniform(-0.001, 0.001)
            lon += random.uniform(-0.001, 0.001)
            
            # Speed varies by time of day
            if 6 <= timestamp.hour <= 9 or 16 <= timestamp.hour <= 19:
                # Rush hour - slower
                speed = random.uniform(20, 60)
            elif 22 <= timestamp.hour or timestamp.hour <= 5:
                # Night - minimal movement
                speed = random.uniform(0, 20)
            else:
                # Normal hours
                speed = random.uniform(30, 80)
            
            gps_data.append((
                f"VEH-{vehicle_id:03d}",
                timestamp,
                lat,
                lon,
                speed,
                random.uniform(0, 360),  # heading
                random.uniform(0, 100),  # altitude
                random.uniform(5, 15)    # gps_accuracy
            ))
        
        current_date += timedelta(days=1)

print(f"Generated {len(gps_data):,} GPS records")

# Create DataFrame
gps_schema = StructType([
    StructField("vehicle_id", StringType(), False),
    StructField("timestamp", TimestampType(), False),
    StructField("latitude", DoubleType(), False),
    StructField("longitude", DoubleType(), False),
    StructField("speed", DoubleType(), True),
    StructField("heading", DoubleType(), True),
    StructField("altitude", DoubleType(), True),
    StructField("gps_accuracy", DoubleType(), True)
])

gps_raw_df = spark.createDataFrame(gps_data, schema=gps_schema)

# Add audit columns
gps_raw_df = gps_raw_df \
    .withColumn("_ingestion_time", current_timestamp()) \
    .withColumn("_source_file", lit("generated_data_improved")) \
    .withColumn("ingestion_date", to_date(col("_ingestion_time")))

print(f"Total GPS records: {gps_raw_df.count():,}")
print(f"Date range: {START_DATE.date()} to {END_DATE.date()}")
print(f"Vehicles: {NUM_VEHICLES}")
display(gps_raw_df.limit(5))

# Write to Bronze Delta table
bronze_gps_table = f"{BRONZE_SCHEMA}.gps_tracking_raw"

gps_raw_df.write \
    .format("delta") \
    .mode("overwrite") \
    .partitionBy("ingestion_date") \
    .option("mergeSchema", "true") \
    .saveAsTable(bronze_gps_table)

print(f"âœ“ GPS data written to: {bronze_gps_table}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 3. Generate Vehicle Telemetry Data (IMPROVED)
# MAGIC 
# MAGIC **Key Improvements:**
# MAGIC - 5 health categories (Excellent, Good, Warning, Poor, Critical)
# MAGIC - Gradual degradation over time
# MAGIC - Correlated sensor readings
# MAGIC - Realistic failure patterns

# COMMAND ----------

print("Generating vehicle telemetry data with improved variation...")

telemetry_data = []

# Assign each vehicle a health category and degradation rate
vehicle_health_profiles = {}
for vehicle_id in range(1, NUM_VEHICLES + 1):
    # Health score: 0.0 (critical) to 1.0 (excellent)
    initial_health = random.random()
    degradation_rate = random.uniform(0.001, 0.005)  # Health degrades over time
    
    vehicle_health_profiles[vehicle_id] = {
        'initial_health': initial_health,
        'degradation_rate': degradation_rate
    }

# Generate telemetry
for vehicle_id in range(1, NUM_VEHICLES + 1):
    current_date = START_DATE
    base_odometer = random.uniform(50000, 150000)
    profile = vehicle_health_profiles[vehicle_id]
    
    day_counter = 0
    
    while current_date <= END_DATE:
        # Health degrades over time
        current_health = profile['initial_health'] - (day_counter * profile['degradation_rate'])
        current_health = max(0.0, min(1.0, current_health))  # Clamp to [0, 1]
        
        for reading in range(READINGS_PER_DAY):
            timestamp = current_date + timedelta(minutes=reading * 10)
            
            # Generate sensor values based on health score
            if current_health < 0.15:  # CRITICAL (15%)
                engine_temp = random.uniform(110, 125)
                oil_pressure = random.uniform(15, 30)
                tire_variance = random.uniform(7, 12)
                battery_voltage = random.uniform(11.0, 12.0)
            elif current_health < 0.35:  # POOR (20%)
                engine_temp = random.uniform(105, 115)
                oil_pressure = random.uniform(25, 40)
                tire_variance = random.uniform(5, 8)
                battery_voltage = random.uniform(11.5, 12.5)
            elif current_health < 0.60:  # WARNING (25%)
                engine_temp = random.uniform(95, 108)
                oil_pressure = random.uniform(35, 50)
                tire_variance = random.uniform(3, 6)
                battery_voltage = random.uniform(12.0, 13.0)
            elif current_health < 0.85:  # GOOD (25%)
                engine_temp = random.uniform(85, 100)
                oil_pressure = random.uniform(45, 60)
                tire_variance = random.uniform(1, 4)
                battery_voltage = random.uniform(12.5, 13.5)
            else:  # EXCELLENT (15%)
                engine_temp = random.uniform(80, 95)
                oil_pressure = random.uniform(50, 65)
                tire_variance = random.uniform(0, 2)
                battery_voltage = random.uniform(13.0, 14.0)
            
            # Add daily variation (hotter in afternoon)
            hour_factor = 1.0 + (0.05 if 12 <= timestamp.hour <= 16 else 0)
            engine_temp *= hour_factor
            
            # Fuel decreases through the day
            fuel_decrease = 100 - (reading * 0.5)
            fuel_level = fuel_decrease if fuel_decrease > 20 else 20
            
            # Calculate tire pressures with variance
            base_tire = 32
            telemetry_data.append((
                f"VEH-{vehicle_id:03d}",
                timestamp,
                engine_temp,
                oil_pressure,
                base_tire + random.uniform(-tire_variance/2, tire_variance/2),  # FL
                base_tire + random.uniform(-tire_variance/2, tire_variance/2),  # FR
                base_tire + random.uniform(-tire_variance/2, tire_variance/2),  # RL
                base_tire + random.uniform(-tire_variance/2, tire_variance/2),  # RR
                fuel_level,
                battery_voltage,
                base_odometer + (day_counter * READINGS_PER_DAY + reading) * 5,
                random.uniform(800, 3000) if fuel_level > 20 else 0,
                random.uniform(10, 80) if fuel_level > 20 else 0,
                random.choice([True, False])
            ))
        
        current_date += timedelta(days=1)
        day_counter += 1
        base_odometer += 720  # ~720 km per day

print(f"Generated {len(telemetry_data):,} telemetry records")

# Show health distribution
health_distribution = {
    'Excellent (>0.85)': sum(1 for v in vehicle_health_profiles.values() if v['initial_health'] > 0.85),
    'Good (0.60-0.85)': sum(1 for v in vehicle_health_profiles.values() if 0.60 <= v['initial_health'] <= 0.85),
    'Warning (0.35-0.60)': sum(1 for v in vehicle_health_profiles.values() if 0.35 <= v['initial_health'] < 0.60),
    'Poor (0.15-0.35)': sum(1 for v in vehicle_health_profiles.values() if 0.15 <= v['initial_health'] < 0.35),
    'Critical (<0.15)': sum(1 for v in vehicle_health_profiles.values() if v['initial_health'] < 0.15)
}

print("\nVehicle health distribution:")
for category, count in health_distribution.items():
    print(f"  {category}: {count} vehicles ({count/NUM_VEHICLES*100:.1f}%)")

# Create DataFrame
telemetry_schema = StructType([
    StructField("vehicle_id", StringType(), False),
    StructField("timestamp", TimestampType(), False),
    StructField("engine_temp", DoubleType(), True),
    StructField("oil_pressure", DoubleType(), True),
    StructField("tire_pressure_fl", DoubleType(), True),
    StructField("tire_pressure_fr", DoubleType(), True),
    StructField("tire_pressure_rl", DoubleType(), True),
    StructField("tire_pressure_rr", DoubleType(), True),
    StructField("fuel_level", DoubleType(), True),
    StructField("battery_voltage", DoubleType(), True),
    StructField("odometer", DoubleType(), True),
    StructField("rpm", DoubleType(), True),
    StructField("throttle_position", DoubleType(), True),
    StructField("brake_status", BooleanType(), True)
])

telemetry_raw_df = spark.createDataFrame(telemetry_data, schema=telemetry_schema)

# Add audit columns
telemetry_raw_df = telemetry_raw_df \
    .withColumn("_ingestion_time", current_timestamp()) \
    .withColumn("_source_file", lit("generated_data_improved")) \
    .withColumn("ingestion_date", to_date(col("_ingestion_time")))

print(f"\nTotal telemetry records: {telemetry_raw_df.count():,}")
display(telemetry_raw_df.limit(5))

# Write to Bronze Delta table
bronze_telemetry_table = f"{BRONZE_SCHEMA}.vehicle_telemetry_raw"

telemetry_raw_df.write \
    .format("delta") \
    .mode("overwrite") \
    .partitionBy("ingestion_date") \
    .option("mergeSchema", "true") \
    .saveAsTable(bronze_telemetry_table)

print(f"âœ“ Telemetry data written to: {bronze_telemetry_table}")

# Verify
record_count = spark.table(bronze_telemetry_table).count()
print(f"âœ“ Verified: {record_count:,} records in table")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 4. Summary

# COMMAND ----------

print("=" * 60)
print("âœ“ Bronze Layer Ingestion Complete (IMPROVED)!")
print("=" * 60)

gps_count = spark.table(f"{BRONZE_SCHEMA}.gps_tracking_raw").count()
telemetry_count = spark.table(f"{BRONZE_SCHEMA}.vehicle_telemetry_raw").count()

print(f"\nâœ“ Tables Created:")
print(f"  - {BRONZE_SCHEMA}.gps_tracking_raw: {gps_count:,} records")
print(f"  - {BRONZE_SCHEMA}.vehicle_telemetry_raw: {telemetry_count:,} records")

print(f"\nâœ“ Data Quality:")
print(f"  - Vehicles: {NUM_VEHICLES}")
print(f"  - Date range: {START_DATE.date()} to {END_DATE.date()} ({(END_DATE - START_DATE).days} days)")
print(f"  - Health categories: 5 (Excellent, Good, Warning, Poor, Critical)")
print(f"  - Degradation: Gradual over time")

print(f"\nâœ“ Improvements:")
print(f"  - 5x more vehicles (500 vs 100)")
print(f"  - 4x more days (30 vs 7)")
print(f"  - 5 health categories (vs 3)")
print(f"  - Realistic degradation patterns")

print(f"\nðŸ“Œ Expected ML Performance:")
print(f"  - F1-Score: 92-95% (was 88%)")
print(f"  - ROC-AUC: 90-95% (was 75%)")
print(f"  - Recall: 95-98% (was 98%)")

print(f"\nðŸ“Œ Next Steps:")
print(f"  1. Run notebook 02_Silver_Transformation.py")
print(f"  2. Run notebook 03_Gold_Aggregation.py")
print(f"  3. Run notebook 06_ML_Predictive_Maintenance.py")
print("=" * 60)

# COMMAND ----------

# MAGIC %md
# MAGIC ---
# MAGIC **Author:** Venkat M  
# MAGIC **Project:** Fleet Optimization & Predictive Maintenance  
# MAGIC **Version:** 2.0 (Improved)  
# MAGIC **Last Updated:** 2026-01-27
